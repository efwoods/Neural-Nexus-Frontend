I don't want to use Redis. I want to use the browser cache instead. 

I want a avatar cache that is a global context and a message cache that is a global context.

Removing Redis Cache:

Great question! Let me break down exactly how the frontend populates and displays messages in this architecture.
Frontend Message Population Flow
There are TWO ways messages appear in the frontend:

1. Initial Load (On Avatar Selection)
When a user selects an avatar or opens the chat, the frontend loads historical messages once:
Step-by-Step:
// In MediaContext.jsx - useEffect hook
useEffect(() => {
  if (activeAvatar && accessToken && user) {
    // 1. Connect WebSocket for real-time updates
    RedisWebSocketService.connect(
      user.user_id,
      activeAvatar.avatar_id,
      accessToken
    );

    // 2. Fetch initial messages (ONE TIME ONLY)
    fetchMessages(); // â† This loads historical messages
    
    return () => {
      RedisWebSocketService.disconnect();
    };
  }
}, [activeAvatar?.avatar_id, accessToken, user?.user_id]);

The fetchMessages() Function:

const fetchMessages = async () => {
  if (!activeAvatar || !accessToken) return;
  
  try {
    // Call DB API to get messages
    const response = await fetch(
      `${getDbHttpsUrl()}/documents/avatars/${activeAvatar.avatar_id}/messages`,
      {
        headers: {
          Authorization: `Bearer ${accessToken}`,
        },
      }
    );

    if (!response.ok) {
      throw new Error('Failed to fetch messages');
    }

    const data = await response.json();
    
    // Populate messages state with historical data
    setMessages((prev) => ({
      ...prev,
      [activeAvatar.avatar_id]: data.messages.map((msg) => ({
        id: msg._id,
        content: msg.message,
        media: msg.media || [],
        sender: msg.sender,
        timestamp: msg.timestamp,
      })),
    }));

    console.log(`Loaded ${data.messages.length} messages from ${data.source}`);
    
  } catch (error) {
    console.error('Failed to fetch messages:', error);
  }
};

What Happens on the Backend?
When frontend calls /avatars/{avatar_id}/messages:

# In message_persistence.py
@router.get("/avatars/{avatar_id}/messages")
async def get_avatar_messages(avatar_id: UUID, ...):
    # 1. Try Redis cache first
    messages = await get_message_cache(redis_client, user_id, avatar_id_str)
    
    # 2. If cache empty, populate from MongoDB
    if not messages:
        messages = await populate_cache_from_db(
            redis_client,
            db.mongo_db,
            user_id,
            avatar_id_str
        )
    
    return {"messages": messages, "source": "cache" or "database"}

So the initial load:

âœ… Checks Redis cache first (fast!)
âœ… If cache empty, loads from MongoDB (last 50 messages)
âœ… Populates cache for future reads
âœ… Returns messages to frontend


2. Real-Time Updates (WebSocket)
After the initial load, NO MORE POLLING. All new messages come via WebSocket:
WebSocket Setup:
// In MediaContext.jsx
useEffect(() => {
  if (activeAvatar && accessToken && user) {
    // Connect to WebSocket
    RedisWebSocketService.connect(
      user.user_id,
      activeAvatar.avatar_id,
      accessToken
    );

    // Define what happens when AI response arrives
    const handleAIResponse = (data) => {
      console.log('Received AI response:', data);
      
      const newMessage = {
        id: data.message_id,
        content: data.message,
        sender: data.sender || 'assistant',
        timestamp: data.timestamp,
        media: []
      };

      // ADD to existing messages (real-time update!)
      setMessages((prev) => ({
        ...prev,
        [activeAvatar.avatar_id]: [
          ...(prev[activeAvatar.avatar_id] || []),
          newMessage  // â† Append new message
        ]
      }));
    };

    // Register the callback
    RedisWebSocketService.onMessage(handleAIResponse);

    // Load initial messages
    fetchMessages();

    // Cleanup on unmount
    return () => {
      RedisWebSocketService.removeMessageListener(handleAIResponse);
      RedisWebSocketService.disconnect();
    };
  }
}, [activeAvatar?.avatar_id, accessToken, user?.user_id]);

WebSocket Connection Details:

// In RedisWebSocketService.js
connect(userId, avatarId, accessToken) {
  const baseUrl = getDbHttpsUrl()
    .replace('https://', 'wss://')
    .replace('http://', 'ws://');
  
  const wsUrl = `${baseUrl}/ws/chat/${userId}/${avatarId}?token=${accessToken}`;
  
  this.ws = new WebSocket(wsUrl);

  this.ws.onopen = () => {
    console.log('âœ… Redis WebSocket connected');
  };

  this.ws.onmessage = (event) => {
    try {
      const data = JSON.parse(event.data);
      console.log('ğŸ“¨ Received AI response via WebSocket:', data);
      
      // Notify all registered callbacks
      this.messageCallbacks.forEach(callback => callback(data));
    } catch (error) {
      console.error('Failed to parse WebSocket message:', error);
    }
  };
}


3. Sending a Message (Optimistic UI Update)
When the user sends a message:

async function sendMessage() {
  if (!activeAvatar || (!inputMessage.trim() && mediaFiles.length === 0))
    return;

  try {
    // STEP 1: Optimistically add user message to UI (instant feedback)
    const tempMessage = {
      id: `temp-${Date.now()}`,
      content: inputMessage,
      sender: sender,
      timestamp: new Date().toISOString(),
      media: mediaFiles.map((f) => ({
        filename: f.name,
        content_type: f.type,
      })),
    };

    setMessages((prev) => ({
      ...prev,
      [activeAvatar.avatar_id]: [
        ...(prev[activeAvatar.avatar_id] || []),
        tempMessage,  // â† User sees their message immediately
      ],
    }));

    // STEP 2: Send to DB API
    const response = await MessageService.saveMessage(
      activeAvatar.avatar_id,
      inputMessage,
      mediaFiles,
      accessToken,
      sender
    );

    if (!response || response.status !== 'success') {
      throw new Error(response?.detail || 'Message post failed');
    }

    console.log('Message sent successfully:', response.message_id);

    // STEP 3: Clear input
    setInputMessage('');
    setMediaFiles([]);

    // STEP 4: AI response will arrive via WebSocket automatically
    // (handleAIResponse callback will add it to messages)
    
  } catch (err) {
    console.error('Failed to send message:', err);
    
    // Remove optimistic message on error
    setMessages((prev) => ({
      ...prev,
      [activeAvatar.avatar_id]: (prev[activeAvatar.avatar_id] || []).filter(
        (msg) => msg.id !== tempMessage.id
      ),
    }));
    
    alert(err.message || 'Failed to send message');
  }
}
```

---

## **Complete Message Flow Visualization**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND FLOW                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. USER SELECTS AVATAR
   â†“
2. INITIAL LOAD (fetchMessages - ONE TIME)
   â”œâ”€ Fetch GET /avatars/{avatar_id}/messages
   â”œâ”€ Receive last 50 messages from Redis cache or MongoDB
   â””â”€ Populate messages state
   
3. WEBSOCKET CONNECTION
   â”œâ”€ Connect to wss://.../ws/chat/{user_id}/{avatar_id}
   â””â”€ Subscribe to "chat:{user_id}:{avatar_id}:new_response"

4. USER TYPES MESSAGE
   â†“
5. OPTIMISTIC UI UPDATE
   â”œâ”€ Add message to UI immediately (temp ID)
   â””â”€ User sees their message instantly
   
6. POST MESSAGE TO DB API
   â”œâ”€ POST /avatars/post_message
   â””â”€ Backend: Save â†’ Cache â†’ Publish to Avatar API

7. WAIT FOR AI RESPONSE (via WebSocket)
   â†“
8. WEBSOCKET RECEIVES MESSAGE
   â”œâ”€ onmessage event fires
   â”œâ”€ Parse JSON data
   â””â”€ Call handleAIResponse callback
   
9. ADD AI RESPONSE TO UI
   â”œâ”€ setMessages with new AI message
   â””â”€ User sees AI response instantly

10. REPEAT 4-9 for each new message

